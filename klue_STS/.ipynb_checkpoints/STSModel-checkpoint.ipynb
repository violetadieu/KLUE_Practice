{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fc6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer,  LoggingHandler, losses, models, util\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "from transformers import AutoModel, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f608a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "modelName=\"klue/bert-base\"\n",
    "tokenizerName=\"klue/bert-base\"\n",
    "embeddingModelName=models.Transformer(modelName)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizerName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99541e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTrainData(path):\n",
    "    trainDataset=[]\n",
    "    with open(path,'rb')as file:\n",
    "        STSdata=json.load(file)\n",
    "    \n",
    "    for item in STSdata:\n",
    "        score=float(item['labels']['label'])/5.0\n",
    "\n",
    "        inputEx=InputExample(\n",
    "        texts=[item[\"sentence1\"],item[\"sentence2\"]],\n",
    "        label=score\n",
    "        )\n",
    "        trainDataset.append(inputEx)\n",
    "    \n",
    "    return trainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d136bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "EPOCH=4\n",
    "outputPath=(modelName+\"_epoch-\"+str(EPOCH)).replace(\"/\",\"-\")\n",
    "outputPath='./outputs/'+outputPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629d79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooling, mean 사용예정\n",
    "pooler = models.Pooling(\n",
    "    embeddingModelName.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True,\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db4209c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(modules=[embeddingModelName, pooler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e327d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName=\"./dataset/klue-sts-v1.1_train.json\"\n",
    "trainDataset=readTrainData(dataName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007ca584",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader=DataLoader(\n",
    "trainDataset,\n",
    "shuffle=True,\n",
    "batch_size=BATCH_SIZE\n",
    ")\n",
    "trainLoss=losses.CosineSimilarityLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d8f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator=EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "trainDataset,\n",
    "name=\"sts-vali\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17f9ce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DESKTOP\\anaconda3\\envs\\a2\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9326e1f797fa420b87c286240a30625c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a5b19f91da42edab636a1f8606c785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550edb7437db441e9ce84a58ec25428b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07439e0903d49528e2208d8e0094896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a7be70c23d4f2e89c180796d18e71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(\n",
    "train_objectives=[(trainDataLoader, trainLoss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=EPOCH,\n",
    "    evaluation_steps=1000,\n",
    "    output_path=outputPath\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8f076c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 손흥민은 어린 나이에 유럽에 진출하였다.\n",
      "\n",
      "<입력 문장과 유사한 5 개의 문장>\n",
      "\n",
      "1: 독일 U-19 리그에서 손흥민은 11경기 6골, 2부 리그에서는 6경기 1골을 넣으며 재능을 인정받아 2010년 6월 17세의 나이로 함부르크의 1군 팀 훈련에 참가, 프리시즌 활약으로 함부르크와 정식 계약을 한 후 10월 18세에 함부르크 1군 소속으로 독일 분데스리가에 데뷔하였다. (유사도: 0.6070)\n",
      "\n",
      "2: 그해 11월 함부르크의 정식 유소년팀 선수 계약을 체결하였으며 독일 U-19 리그 4경기 2골을 넣고 2군 리그에 출전을 시작했다. (유사도: 0.5975)\n",
      "\n",
      "3: 1년간의 유학 후 2009년 8월 한국으로 돌아온 후 10월에 개막한 FIFA U-17 월드컵에 출전하여 3골을 터트리며 한국을 8강으로 이끌었다. (유사도: 0.4670)\n",
      "\n",
      "4: 함부르크 유스팀 주전 공격수로 2008년 6월 네덜란드에서 열린 4개국 경기에서 4게임에 출전, 3골을 터뜨렸다. (유사도: 0.4306)\n",
      "\n",
      "5: 춘천 부안초등학교를 졸업했고, 춘천 후평중학교에 입학한 후 2학년때 원주 육민관중학교 축구부에 들어가기 위해 전학하여 졸업하였으며, 2008년 당시 FC 서울의 U-18팀이었던 동북고등학교 축구부에서 선수 활동 중 대한축구협회 우수선수 해외유학 프로젝트에 선발되어 2008년 8월 독일 분데스리가의 함부르크 유소년팀에 입단하였다. (유사도: 0.4037)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = ['어제는 아내의 생일이었다', '생일을 맞이하여 아침을 준비하겠다고 오전 8시 30분부터 음식을 준비하였다. 주된 메뉴는 스테이크와 낙지볶음, 미역국, 잡채, 소야 등이었다', '스테이크는 자주 하는 음식이어서 자신이 준비하려고 했다', '앞뒤도 1분씩 3번 뒤집고 래스팅을 잘 하면 육즙이 가득한 스테이크가 준비되다', '아내도 그런 스테이크를 좋아한다. 그런데 상상도 못한 일이 벌이지고 말았다', '보통 시즈닝이 되지 않은 원육을 사서 스테이크를 했는데, 이번에는 시즈닝이 된 부챗살을 구입해서 했다', '그런데 케이스 안에 방부제가 들어있는 것을 인지하지 못하고 방부제와 동시에 프라이팬에 올려놓을 것이다', '그것도 인지 못한 체... 앞면을 센 불에 1분을 굽고 뒤집는 순간 방부제가 함께 구어진 것을 알았다', '아내의 생일이라 맛있게 구워보고 싶었는데 어처구니없는 상황이 발생한 것이다', '방부제가 센 불에 녹아서 그런지 물처럼 흘러내렸다', ' 고민을 했다. 방부제가 묻은 부문만 제거하고 다시 구울까 했는데 방부제에 절대 먹지 말라는 문구가 있어서 아깝지만 버리는 방향을 했다', '너무나 안타까웠다', '아침 일찍 아내가 좋아하는 스테이크를 준비하고 그것을 맛있게 먹는 아내의 모습을 보고 싶었는데 전혀 생각지도 못한 상황이 발생해서... 하지만 정신을 추스르고 바로 다른 메뉴로 변경했다', '소야, 소시지 야채볶음..', '아내가 좋아하는지 모르겠지만 냉장고 안에 있는 후랑크소세지를 보니 바로 소야를 해야겠다는 생각이 들었다. 음식은 성공적으로 완성이 되었다', '40번째를 맞이하는 아내의 생일은 성공적으로 준비가 되었다', '맛있게 먹어 준 아내에게도 감사했다', '매년 아내의 생일에 맞이하면 아침마다 생일을 차려야겠다. 오늘도 즐거운 하루가 되었으면 좋겠다', '생일이니까~']\n",
    "document_embeddings = model.encode(docs)\n",
    "\n",
    "query = \"손흥민은 어린 나이에 유럽에 진출하였다.\"\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "top_k = min(5, len(docs))\n",
    "\n",
    "# 입력 문장 - 문장 후보군 간 코사인 유사도 계산 후,\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, document_embeddings)[0]\n",
    "\n",
    "# 코사인 유사도 순으로 `top_k` 개 문장 추출\n",
    "top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "print(f\"입력 문장: {query}\")\n",
    "print(f\"\\n<입력 문장과 유사한 {top_k} 개의 문장>\\n\")\n",
    "\n",
    "for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "    print(f\"{i+1}: {docs[idx]} {'(유사도: {:.4f})'.format(score)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac4eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
