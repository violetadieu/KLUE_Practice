{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cedbf843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KLUE QA Dataset과 Roberta-large모델을 활용한 학습 예제 입니다.\n",
    "\n",
    "import json\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import AutoTokenizer,AutoModelForQuestionAnswering,AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "157c55a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dataset/klue-mrc-v1.1_train.json\", 'rb') as f:\n",
    "    klue_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10f3c232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '제주도 장마 시작 … 중부는 이달 말부터',\n",
       " 'paragraphs': [{'context': '올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.',\n",
       "   'qas': [{'question': '북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?',\n",
       "     'answers': [{'text': '한 달가량', 'answer_start': 478},\n",
       "      {'text': '한 달', 'answer_start': 478}],\n",
       "     'question_type': 1,\n",
       "     'is_impossible': False,\n",
       "     'guid': 'klue-mrc-v1_train_12759'}]}],\n",
       " 'news_category': '종합',\n",
       " 'source': 'hankyung'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_dict[\"data\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22bfcccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data를 읽어서 각 feature 별로 전처리하는 함수\n",
    "def readData(path):\n",
    "    with open(path,'rb')as file:\n",
    "        MRCdata=json.load(file)\n",
    "    #data 구성\n",
    "    #context - 문장\n",
    "    #question - 질문\n",
    "    #answer - 정답\n",
    "    \n",
    "    contexts=list()\n",
    "    \n",
    "    questions=list()\n",
    "    answers=list()\n",
    "    \n",
    "    #하나의 문장에 여러 질문이 있을 수 있고, 질문이 여러개면 답변도 여러개이기 때문에 4중for문 사용\n",
    "    for item in tqdm(MRCdata[\"data\"]):\n",
    "        for passage in item['paragraphs']:\n",
    "            context=passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question=qa['question']\n",
    "                for ans in qa['answers']:\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(ans)\n",
    "    return contexts,questions,answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac9fe1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset에 정답의 끝나는 index도 추가하는 함수\n",
    "def endIdx(answers,contexts):\n",
    "    for answer,context in zip(answers,contexts):\n",
    "        ansText=answer['text']\n",
    "        startIdx=answer['answer_start']\n",
    "        endIdx=startIdx+len(ansText)\n",
    "        \n",
    "        answer['answer_end']=endIdx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a44c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#토크나이징, roberta-large사용\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "784f2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KlueMRCDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, contexts, questions, answers, modelMaxPositionEmbedings, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.answers = answers\n",
    "        self.questions = questions\n",
    "        self.contexts = contexts\n",
    "        self.model_max_position_embedings = modelMaxPositionEmbedings\n",
    "        self.encodings = self.tokenizer(self.contexts, \n",
    "                                        self.questions,\n",
    "                                        max_length=512,\n",
    "                                        truncation=True,\n",
    "                                        padding=\"max_length\",\n",
    "                                        return_token_type_ids=False)\n",
    "        self.addTokenPositions()\n",
    "        \n",
    "    def addTokenPositions(self):\n",
    "        startPositions = []\n",
    "        endPositions = []\n",
    "        for i in range(len(self.answers)):\n",
    "            startPositions.append(self.encodings.char_to_token(i, self.answers[i]['answer_start']))\n",
    "            endPositions.append(self.encodings.char_to_token(i, self.answers[i]['answer_end'] - 1))\n",
    "\n",
    "            # positions 값이 None 값이라면, answer가 포함된 context가 잘렸다는 의미\n",
    "            if startPositions[-1] is None:\n",
    "                startPositions[-1] = self.model_max_position_embedings\n",
    "            if endPositions[-1] is None:\n",
    "                endPositions[-1] = self.model_max_position_embedings\n",
    "\n",
    "        self.encodings.update({'startPositions': startPositions, 'endPositions': endPositions})\n",
    "\n",
    "        \n",
    "    def get_data(self):\n",
    "        return {\"contexts\":self.contexts, 'questions':self.questions, 'answers':self.answers}\n",
    "    \n",
    "    \n",
    "    def get_encodings(self):\n",
    "        return self.encodings\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key:torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1365cd23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6834b20e229d400db3986d76f12c8dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#훈련 data 전처리\n",
    "contexts,questions,answers=readData(\"./dataset/klue-mrc-v1.1_train.json\")\n",
    "endIdx(answers,contexts)\n",
    "trainDataset=KlueMRCDataset(contexts,questions,answers,512,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f6aaf5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#model 가저오기\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "823654c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼파라미터 정의\n",
    "EPOCH=3\n",
    "LEARNING_RATE=5e-5\n",
    "BATCH_SIZE=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc7da0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 훈련 실행함수(AdamW사용)\n",
    "def train_runner(model, dataset, batch_size, num_train_epochs, learning_rate):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_dataloader = DataLoader(dataset=dataset, batch_size=batch_size)\n",
    "    global_total_step = len(train_dataloader) * num_train_epochs\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "    with tqdm(total=global_total_step, unit='step') as t:\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "        for epoch in range(num_train_epochs):\n",
    "            for batch in train_dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                startPositions = batch['startPositions'].to(device)\n",
    "                endPositions = batch['endPositions'].to(device)\n",
    "                outputs = model(input_ids,\n",
    "                             attention_mask=attention_mask,\n",
    "                             start_positions=startPositions,\n",
    "                             end_positions=endPositions)\n",
    "                loss = outputs.loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                batch_loss = loss.item() * len(input_ids)\n",
    "                total += len(input_ids)\n",
    "                total_loss += batch_loss\n",
    "                global_total_step += 1\n",
    "                t.set_postfix(loss=\"{:.6f}\".format(total_loss / total), batch_loss=\"{:.6f}\".format(batch_loss))\n",
    "                t.update(1)\n",
    "                \n",
    "                del input_ids\n",
    "                del attention_mask\n",
    "                del startPositions\n",
    "                del endPositions\n",
    "                del outputs\n",
    "                del loss\n",
    "    model.save_pretrained(\"./outputs/klue_output_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b849c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44a73cc65314c76b429ef2db48c56fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6624 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#모델 훈련 실행\n",
    "train_runner(model,trainDataset, BATCH_SIZE, EPOCH, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77a04b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
