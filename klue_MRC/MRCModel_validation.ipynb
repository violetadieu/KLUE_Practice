{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cedbf843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KLUE QA Dataset과 Roberta-large모델을 활용한 학습 예제 입니다.\n",
    "\n",
    "import json\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import AutoTokenizer,AutoModelForQuestionAnswering,AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82df87f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDevData(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        klue_dict = json.load(f)\n",
    "\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for group in tqdm(klue_dict['data']):\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                temp_answer = []\n",
    "                for answer in qa['answers']:\n",
    "                    temp_answer.append(answer['text'])\n",
    "                if len(temp_answer) != 0:\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(temp_answer)\n",
    "\n",
    "    return contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "153ea319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(contexts, questions):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for context, question in zip(contexts, questions):\n",
    "            encodings = tokenizer(context, question, max_length=512, truncation=True,\n",
    "                                     padding=\"max_length\", return_token_type_ids=False)\n",
    "            encodings = {key: torch.tensor([val]) for key, val in encodings.items()}\n",
    "            \n",
    "            input_ids = encodings[\"input_ids\"].to(device)\n",
    "            attention_mask = encodings[\"attention_mask\"].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "            token_start_index, token_end_index = start_logits.argmax(dim=-1), end_logits.argmax(dim=-1)\n",
    "            pred_ids = input_ids[0][token_start_index: token_end_index + 1]\n",
    "            pred = tokenizer.decode(pred_ids)\n",
    "            result.append(pred)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c88385d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_evalutate(preds, reals):\n",
    "    total = len(preds)\n",
    "    exact_match = 0\n",
    "    for pred, real in zip(preds, reals):\n",
    "        if pred in real:\n",
    "            exact_match += 1\n",
    "    \n",
    "    return (exact_match/total) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dba5ab31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a116ac417f42f688ebc4a1841e5c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5075 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#훈련 data 전처리\n",
    "dev_contexts ,dev_questions ,dev_answers =readDevData(\"./dataset/klue-mrc-v1.1_dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f60c62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MRCModel에서 훈련을 완료한 model 가저오기 및 tokenizer 설정\n",
    "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"outputs/base_klue_data_model_epoch_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = prediction(dev_contexts, dev_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ebef69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
